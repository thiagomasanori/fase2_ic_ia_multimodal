{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (from requests) (2024.8.30)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /Users/thiagohata/Library/Python/3.9/lib/python/site-packages (9.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests\n",
    "! pip install pillow\n",
    "import requests\n",
    "import os, sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import skimage, skimage.io\n",
    "import pprint\n",
    "\n",
    "import warnings\n",
    "from numpy import ndarray\n",
    "from torchxrayvision.utils import normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xray_dcm(path: os.PathLike) -> ndarray:\n",
    "    \"\"\"read a dicom-like file and convert to numpy array \n",
    "\n",
    "    Args:\n",
    "        path (PathLike): path to the dicom file\n",
    "\n",
    "    Returns:\n",
    "        ndarray: 2D single array image for a dicom image scaled between -1024, 1024\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pydicom\n",
    "    except ImportError:\n",
    "        raise Exception(\"Missing Package Pydicom. Try installing it by running `pip install pydicom`.\")\n",
    "\n",
    "    # get the pixel array\n",
    "    ds = pydicom.dcmread(path, force=True)\n",
    "\n",
    "    # we have not tested RGB, YBR_FULL, or YBR_FULL_422 yet.\n",
    "    if ds.PhotometricInterpretation not in ['MONOCHROME1', 'MONOCHROME2']:\n",
    "        raise NotImplementedError(f'PhotometricInterpretation `{ds.PhotometricInterpretation}` is not yet supported.')\n",
    "\n",
    "    data = ds.pixel_array\n",
    "    \n",
    "    # LUT for human friendly view\n",
    "    data = pydicom.pixel_data_handlers.util.apply_voi_lut(data, ds, index=0)\n",
    "\n",
    "    # `MONOCHROME1` have an inverted view; Bones are black; background is white\n",
    "    # https://web.archive.org/web/20150920230923/http://www.mccauslandcenter.sc.edu/mricro/dicom/index.html\n",
    "    if ds.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        warnings.warn(f\"Coverting MONOCHROME1 to MONOCHROME2 interpretation for file: {path}. Can be avoided by setting `fix_monochrome=False`\")\n",
    "        data = data.max() - data\n",
    "\n",
    "    # normalize data to [-1024, 1024]\n",
    "    data = normalize(data, data.max())\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/thiagohata/Documents/dicom_samples'\n",
    "\n",
    "#def walk_in_folder(folder_path):\n",
    "#    count = 0\n",
    "#    for root, dirs, files in os.walk(folder_path):\n",
    "#        for file_name in files:\n",
    "#            if file_name.endswith(\".dcm\"):  # You can adjust this to detect DICOM files without extensions\n",
    "#                file_path = os.path.join(root, file_name)\n",
    "#                count+=1\n",
    "#                #print(count)\n",
    "#                #upload_dicom_file(file_path, orthanc_url)\n",
    "#                return(file_path)\n",
    "\n",
    "def walk_in_folder(folder_path):\n",
    "    count = 0\n",
    "    dicom_arrays = []  # List to store processed DICOM arrays\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".dcm\"):  # Detecting DICOM files by extension\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                count += 1\n",
    "                #print(f\"Processing file {count}: {file_path}\")\n",
    "                \n",
    "                # Call the read_xray_dcm function to process the DICOM file\n",
    "                dicom_array = read_xray_dcm(file_path)\n",
    "                \n",
    "                # Add the processed array to the list\n",
    "                dicom_arrays.append(dicom_array)\n",
    "    \n",
    "    # Return the list of all processed DICOM arrays\n",
    "    return dicom_arrays\n",
    "\n",
    "# images_list as a numpy_array\n",
    "dicom_images = walk_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pil_img_list = []\n",
    "## Convert list of NumPy array to a Pillow Image\n",
    "#def convert_array(dicom_images):\n",
    "#    for i in range(len(dicom_images)):\n",
    "#        image = Image.fromarray(dicom_images[i])\n",
    "#\n",
    "#        img = skimage.io.imread(image)\n",
    "#        img = xrv.datasets.normalize(img, 255) \n",
    "#        # Check that images are 2D arrays\n",
    "#        if len(img.shape) > 2:\n",
    "#            img = img[:, :, 0]\n",
    "#        if len(img.shape) < 2:\n",
    "#            print(\"error, dimension lower than 2 for image\")\n",
    "#        \n",
    "#        # Add color channel\n",
    "#        img = img[None, :, :]\n",
    "#        pil_img_list.append(img)\n",
    "#    return(pil_img_list)\n",
    "#convert_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-f F] [-weights WEIGHTS] [-feats] [-cuda]\n",
      "                             [-resize]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/thiagohata/Library/Jupyter/runtime/kernel-v2-1166XZuPmKAVlIZe.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "pil_img_list = []\n",
    "def convert_array(dicom_images):\n",
    "    for i in range(len(dicom_images)):\n",
    "        image = Image.fromarray(dicom_images[i])\n",
    "        pil_img_list.append(image)\n",
    "    return(pil_img_list)\n",
    "\n",
    "convert_array(dicom_images)\n",
    "\n",
    "def process_image(pil_image):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-f', type=str, default=\"\", help='')\n",
    "    #parser.add_argument('img_path', type=str)\n",
    "    parser.add_argument('-weights', type=str,default=\"densenet121-res224-all\")\n",
    "    parser.add_argument('-feats', default=False, help='', action='store_true')\n",
    "    parser.add_argument('-cuda', default=False, help='', action='store_true')\n",
    "    parser.add_argument('-resize', default=False, help='', action='store_true')\n",
    "\n",
    "    cfg = parser.parse_args()\n",
    "\n",
    "    #img = skimage.io.imread(\"/Users/thiagohata/Downloads/dicom_samples/id_0a0c2c8f-a36a1e82-a4857225-5a2af2a6-c7be16c1/Study_12840378.32185825.64169999.71049659.46899097/Series_60731327.33236805.18319358.84233616.48423037\")\n",
    "\n",
    "    img = skimage.io.imread(pil_image)\n",
    "    img = xrv.datasets.normalize(img, 255)  \n",
    "\n",
    "    # Check that images are 2D arrays\n",
    "    if len(img.shape) > 2:\n",
    "        img = img[:, :, 0]\n",
    "    if len(img.shape) < 2:\n",
    "        print(\"error, dimension lower than 2 for image\")\n",
    "\n",
    "    # Add color channel\n",
    "    img = img[None, :, :]\n",
    "\n",
    "    # the models will resize the input to the correct size so this is optional.\n",
    "    if cfg.resize:\n",
    "        transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                                    xrv.datasets.XRayResizer(224)])\n",
    "    else:\n",
    "        transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop()])\n",
    "\n",
    "    img = transform(img)\n",
    "\n",
    "\n",
    "    model = xrv.models.get_model(cfg.weights)\n",
    "\n",
    "    output = {}\n",
    "    with torch.no_grad():\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        if cfg.cuda:\n",
    "            img = img.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        if cfg.feats:\n",
    "            feats = model.features(img)\n",
    "            feats = F.relu(feats, inplace=True)\n",
    "            feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "            output[\"feats\"] = list(feats.cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "        preds = model(img).cpu()\n",
    "        output[\"preds\"] = dict(zip(xrv.datasets.default_pathologies,preds[0].detach().numpy()))\n",
    "\n",
    "    if cfg.feats:\n",
    "        print(output)\n",
    "    else:\n",
    "        pprint.pprint(output)\n",
    "\n",
    "for i in pil_img_list:\n",
    "    process_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchxrayvision as xrv\n",
    "import skimage, torch, torchvision\n",
    "\n",
    "# Prepare the image:\n",
    "img = skimage.io.imread(\"16747_3_1.jpg\")\n",
    "img = xrv.datasets.normalize(img, 255) # convert 8-bit image to [-1024, 1024] range\n",
    "img = img.mean(2)[None, ...] # Make single color channel\n",
    "\n",
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
    "\n",
    "img = transform(img)\n",
    "img = torch.from_numpy(img)\n",
    "\n",
    "# Load model and process image\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "outputs = model(img[None,...]) # or model.features(img[None,...]) \n",
    "\n",
    "# Print results\n",
    "dict(zip(model.pathologies,outputs[0].detach().numpy()))\n",
    "\n",
    "{'Atelectasis': 0.32797316,\n",
    " 'Consolidation': 0.42933336,\n",
    " 'Infiltration': 0.5316924,\n",
    " 'Pneumothorax': 0.28849724,\n",
    " 'Edema': 0.024142697,\n",
    " 'Emphysema': 0.5011832,\n",
    " 'Fibrosis': 0.51887786,\n",
    " 'Effusion': 0.27805611,\n",
    " 'Pneumonia': 0.18569896,\n",
    " 'Pleural_Thickening': 0.24489835,\n",
    " 'Cardiomegaly': 0.3645515,\n",
    " 'Nodule': 0.68982,\n",
    " 'Mass': 0.6392845,\n",
    " 'Hernia': 0.00993878,\n",
    " 'Lung Lesion': 0.011150705,\n",
    " 'Fracture': 0.51916164,\n",
    " 'Lung Opacity': 0.59073937,\n",
    " 'Enlarged Cardiomediastinum': 0.27218717}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
